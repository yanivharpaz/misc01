I'll help you modify the project to use Kafka Connect instead of the custom consumer. Kafka Connect is a better choice for this use case as it provides built-in fault tolerance, scalability, and offset management.

First, let's create a connector configuration class:

Now add these dependencies to your build.gradle:
```groovy
dependencies {
    implementation 'org.apache.kafka:connect-api:3.2.0'
    implementation 'org.apache.kafka:connect-json:3.2.0'
    // ... existing dependencies
}
```

And create a connector configuration file (elasticsearch-connector.properties):
```properties
name=elasticsearch-sink
connector.class=org.example.connector.ElasticsearchSinkConnector
tasks.max=1
topics=my-topic

# Elasticsearch configuration
elasticsearch.host=localhost
elasticsearch.port=9200
elasticsearch.scheme=http
index.prefix=prd_a_

# Batch configuration
batch.size=1000
batch.timeout.ms=5000

# Error handling
errors.tolerance=all
errors.deadletterqueue.topic.name=my-topic-dlq
```

Key changes:
1. Using Kafka Connect framework instead of custom consumer
2. Built-in support for:
   - Distributed mode
   - REST API for management
   - Configuration validation
   - Offset management
   - Error handling
   - Monitoring

To run the connector:
1. Standalone mode:
```bash
connect-standalone.sh connect-standalone.properties elasticsearch-connector.properties
```

2. Distributed mode (using REST API):
```bash
curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d @elasticsearch-connector.json
```

Would you like me to add:
1. More error handling
2. Monitoring capabilities
3. Configuration validation
4. Unit tests for the connector?
