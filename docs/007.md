Detailed implementation plan along with the required Java classes and the code for building your Java application with the described functionality.

---

### Key Java Classes to Use
1. **Kafka Consumer/Producer**:
   - Use `org.apache.kafka.clients.consumer.KafkaConsumer` to read messages from Kafka.
   - Use `org.apache.kafka.clients.producer.KafkaProducer` to send messages to the DLQ topic.
   
2. **Elasticsearch RestHighLevelClient**:
   - Use `RestHighLevelClient` to interact with Elasticsearch for writing data and managing aliases.

3. **Jackson**:
   - Use `com.fasterxml.jackson.databind.ObjectMapper` for JSON parsing.

4. **Map for Alias Cache**:
   - Use a `ConcurrentHashMap` to cache Elasticsearch aliases for efficient lookups.

---

### Code Implementation

```java
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.elasticsearch.action.admin.indices.alias.IndicesAliasesRequest;
import org.elasticsearch.action.index.IndexRequest;
import org.elasticsearch.client.RequestOptions;
import org.elasticsearch.client.RestHighLevelClient;
import org.elasticsearch.client.indices.CreateIndexRequest;
import org.elasticsearch.common.xcontent.XContentType;
import com.fasterxml.jackson.databind.ObjectMapper;
import org.apache.http.HttpHost;
import org.elasticsearch.client.RestClient;

import java.time.Duration;
import java.util.Collections;
import java.util.Map;
import java.util.Properties;
import java.util.concurrent.ConcurrentHashMap;

public class KafkaToElasticsearchApp {
    private static final String KAFKA_TOPIC = "your-input-topic";
    private static final String DLQ_TOPIC = "your-dlq-topic";
    private static final String ES_ALIAS = "your-es-alias";
    private static final String ES_INDEX_PREFIX = "your-index-";
    private final KafkaConsumer<String, String> kafkaConsumer;
    private final KafkaProducer<String, String> kafkaProducer;
    private final RestHighLevelClient esClient;
    private final ObjectMapper objectMapper;
    private final Map<String, String> aliasCache;

    public KafkaToElasticsearchApp(Properties kafkaProperties, Properties producerProperties) {
        this.kafkaConsumer = new KafkaConsumer<>(kafkaProperties);
        this.kafkaConsumer.subscribe(Collections.singletonList(KAFKA_TOPIC));
        this.kafkaProducer = new KafkaProducer<>(producerProperties);
        this.esClient = new RestHighLevelClient(
                RestClient.builder(new HttpHost("localhost", 9200, "http"))
        );
        this.objectMapper = new ObjectMapper();
        this.aliasCache = new ConcurrentHashMap<>();
    }

    public void run() {
        while (true) {
            ConsumerRecords<String, String> records = kafkaConsumer.poll(Duration.ofMillis(100));
            for (ConsumerRecord<String, String> record : records) {
                try {
                    Map<String, Object> data = objectMapper.readValue(record.value(), Map.class);
                    String indexName = getOrCreateAlias(ES_ALIAS);
                    writeToElasticsearch(indexName, data);
                } catch (Exception e) {
                    writeToDLQ(record.value());
                }
            }
        }
    }

    private String getOrCreateAlias(String alias) throws Exception {
        if (!aliasCache.containsKey(alias)) {
            if (!aliasExists(alias)) {
                createAlias(alias);
            }
            aliasCache.put(alias, alias);
        }
        return aliasCache.get(alias);
    }

    private boolean aliasExists(String alias) throws Exception {
        return esClient.indices().exists(new org.elasticsearch.client.indices.GetIndexRequest(alias), RequestOptions.DEFAULT);
    }

    private void createAlias(String alias) throws Exception {
        String indexName = ES_INDEX_PREFIX + System.currentTimeMillis();
        CreateIndexRequest createIndexRequest = new CreateIndexRequest(indexName);
        esClient.indices().create(createIndexRequest, RequestOptions.DEFAULT);

        IndicesAliasesRequest aliasesRequest = new IndicesAliasesRequest();
        IndicesAliasesRequest.AliasActions aliasAction = IndicesAliasesRequest.AliasActions.add()
                .index(indexName)
                .alias(alias);
        aliasesRequest.addAliasAction(aliasAction);
        esClient.indices().updateAliases(aliasesRequest, RequestOptions.DEFAULT);
    }

    private void writeToElasticsearch(String indexName, Map<String, Object> data) throws Exception {
        IndexRequest request = new IndexRequest(indexName)
                .source(data, XContentType.JSON);
        esClient.index(request, RequestOptions.DEFAULT);
    }

    private void writeToDLQ(String message) {
        kafkaProducer.send(new ProducerRecord<>(DLQ_TOPIC, message));
    }

    public void close() throws Exception {
        kafkaConsumer.close();
        kafkaProducer.close();
        esClient.close();
    }

    public static void main(String[] args) {
        Properties kafkaConsumerProperties = new Properties();
        kafkaConsumerProperties.put("bootstrap.servers", "localhost:9092");
        kafkaConsumerProperties.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        kafkaConsumerProperties.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        kafkaConsumerProperties.put("group.id", "kafka-to-es-group");

        Properties kafkaProducerProperties = new Properties();
        kafkaProducerProperties.put("bootstrap.servers", "localhost:9092");
        kafkaProducerProperties.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        kafkaProducerProperties.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        try (KafkaToElasticsearchApp app = new KafkaToElasticsearchApp(kafkaConsumerProperties, kafkaProducerProperties)) {
            app.run();
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
```

---

### Key Features of the Code
1. **Alias Cache**:
   - Uses a `ConcurrentHashMap` for caching aliases to reduce Elasticsearch requests.

2. **Error Handling**:
   - Catches exceptions and sends failed messages to the DLQ topic using Kafka producer.

3. **Elasticsearch Alias Management**:
   - Checks if the alias exists; if not, it creates the alias and maps it to a new index.

4. **JSON Parsing**:
   - Utilizes Jackson's `ObjectMapper` to handle JSON payloads from Kafka messages.

5. **Graceful Shutdown**:
   - Ensures Kafka consumers, producers, and Elasticsearch clients are closed properly.

---

### Gradle Dependencies
Add the following dependencies to your `build.gradle` file:
```groovy
dependencies {
    implementation 'org.apache.kafka:kafka-clients:2.0.0'
    implementation 'org.elasticsearch.client:elasticsearch-rest-high-level-client:6.8.0'
    implementation 'com.fasterxml.jackson.core:jackson-databind:2.15.2'
}
```

---

This implementation aligns with your requirements, ensuring efficient alias management, proper error handling, and Kafka integration. 