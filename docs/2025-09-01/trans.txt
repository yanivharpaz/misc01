Working with AWS CloudFormation
Introducing AWS CloudFormation
Hi there, and welcome to our course, AWS Infrastructure as Code with CloudFormation. My name is Mike Brown, and I'm going to be guiding you through this course. In this course, we'll be taking a detailed look at AWS CloudFormation and how to work with it to implement Infrastructure as Code. We'll discuss CloudFormation best practice and discuss how to implement workflows to remediate any unnecessary or accidentally made changes to our infrastructure that is controlled by AWS CloudFormation. Throughout this course, we'll discuss the requirements of a fictional company, Globomatics. Globomantics is a global healthcare organization who already use many services in AWS. As Globomantics' usage of AWS service increased, they have found that they are spending more and more time on the deployment and management of infrastructure, instead of focusing on innovations. Your job is to identify how Globomantics can adopt an Infrastructure as Code strategy to help make their infrastructure management more efficient and more scalable. As we go through this course, try and relate what Globomantics are going through to your organization. Doing this will help you learn topics quicker and retain information for longer. Globomantics problem: Current manual deployment methods are becoming time consuming as Globomantics scale up their use of AWS services, and manual deployment of infrastructure has led to inconsistencies in the configuration of infrastructure elements. This is to be expected if you're manually deploying and configuring infrastructure at scale. We're all human. Errors will be made, particularly, if we expect to deploy services at scale within tight time limits. Where we can, we need to deploy things consistently based on our own and industry standards. We want to deploy at speed without the same chance of errors that manual configuration brings, and we want to encourage collaboration, instead of individual engineers working on manual deployments in isolation. After all, only one engineer can actually click the buttons and select Next during a manual deployment. To do this, we adopt an Infrastructure as Code approach, and AWS, that means using AWS CloudFormation. We begin by creating templates. Templates can be created in any text editor, and AWS offers a graphical tool called Infrastructure Composer. Infrastructure Composer might make it easier for you to create templates while you're learning AWS CloudFormation. You can also create templates using development platforms like Visual Studio and PyCharm with the appropriate address SDK installed. This allows you to take advantage of syntax highlighting, autocompletion, and error detection. Templates can be written using JSON or YAML formats. Here's an example of a CloudFormation template written in JSON. What do you think it does? This template deploys a VPC with a single subnet. In this template, we have a Resources section. The Resources section is the only required section in a CloudFormation template. The Resources section describes the resources that you want to deploy or work with. Each resource is given a logical ID. The first resource being deployed here is a VPC, and we have given the VPC a logical ID of global VPC. Everything inside this section is used to deploy and customize the VPC. Probably the most important piece of information here is the type. In the global VPC section, we're calling a type of AWS EC2 VPC. This is a CloudFormation type. This particular type understands all the APIs needed to create, manage, and ultimately delete VPCs. Using types means that we don't need to know how to interact with all the APIs needed to create a worker resource. We just call the correct type and then customize the type by providing properties. Here, in the Global VPC section, we can see a group of properties that will customize the type. Some properties like the CIDR block are acquired by the type, and some like the tags property are optional. We include all the properties we need for our new VPC. You can find details of all the types and the properties that AWS make available in the AWS CloudFormation documentation. Once we have all the properties we need for the global VPC section, we can move on to the next section. In this example, we have a section with a logical ID of global subnet that use the type of AWS EC2 subnet, and we've included all the properties we need to configure our new subnet. Your CloudFormation templates will have resource sections that might include dozens of resources and their properties. Templates are used to create CloudFormation stacks. A CloudFormation stack is a collection of AWS resources that you manage as a single unit. A confirmation stack might be deploying or working with a VPC v2 subnets, plus 10 EC2 instances, an RDS database, and several security groups. If you can deploy and work with resources manually, you can also deploy and work them with a CloudFormation stack. Essentially, the stack is used to deploy the AWS resources described in the template. These resources can then be updated and deleted as a single unit. If we have a template that correctly deploys that infrastructure today, it can be used over and over again to correctly deploy the infrastructure in the future. Given its consistency, fewer errors, and DevOp teams can work collaboratively with templates stored in version control systems like GitHub or AWS CodeCommit.

Demonstration: Creating Stacks with the AWS Management Console
Before we connect to the AWS Management Console, let's first take a look at the template we'll be using to create a CloudFormation stack, and here it is. In this template, we have the required section, the Resources section, and in this Resources section, we'll be deploying two resources. This first resource has been given an ID of GloboVPC, and is using a resource type of AWS EC2 VPC, and this resource understands everything about VPC APIs. We provide a set of properties, including the required property of the CIDR block for the VPC, and we provide a name tag. The second resource has an ID of GlobalSubnet, it uses a resource type of AWS EC2 Subnet, and in its properties, we provide a CidrBlock for subnet, the availability zone that the subnet should be deployed to, a name tag, and the VPC ID property. Because our VPC is being created by the stack, we can't hard code in an ID for something that doesn't exist yet, so instead, we use a reference, a reference to the logical ID of the resource where this value should be taken from. So once the stack deploys the global VPC resource, the stack can grab the VPC ID and insert it into the VPC ID property. In this stack, we've also used the DependsOn value. Here, we're saying that this resource, GloboSubnet, depends on the Global VPC resource to be deployed before starting the deployment of GloboSubnet. I've logged into my AWS account and I'm in the CloudFormation dashboard. Here, I can select Create stack. The first step is to provide a template for our new stack. We can build a template here using Infrastructure Composer or choose an existing template. Our template already exists and it exists locally, so I'm going to select Upload a template file. Then I'm going to choose file, browse my local computer, and select the correct template. And as you can see, it's going to upload that template to a bucket inside S3. If I select Next, I can provide a name for my stack, and then Next. We can provide additional tags, we can attach a rule if a rule is required to perform our stack operations, and we can select what happens if there's a stack failure. By default, if it is a failure, all configuration changes will be rolled back, but you can choose to retain any successfully provisioned resources. I'll leave things set to roll back all stack resources. Scrolling down, I don't need to configure any additional settings. So I select Next. We can review our configuration, and if we're happy, select Submit. Once submitted, we should see our stack create in progress. If I just adjust the screen a little bit here and refresh the Events section, we can see a timeline of events for this stack. From Stack create in progress, we can see it moved on to the global VPC resource. Once completed, it moved on to creating the global subnet resource, and once that was completed, the stat was marked as create complete. If I go look at the VPC dashboard and then choose your VPCs, I can see that the global VPC was created, and if I select Subnets, here, you can see our newly‑created subnet. If I jump back to CloudFormation, I then select our newly‑created stack, GloboStack1, we can see properties such as resources, so we can see the list of resources that were created. This list includes their logical ID from the stack, then the physical ID that was assigned after the resource was created. We can also see template. So it shows the details of the template that was used to create the stack. If I select View in Infrastructure Composer, we can see a graphical representation of our stack. Here shows the VPC, the subnet, and their relationship to each other. You can use this tool to create templates from scratch, as well as loading in and visualizing existing templates and editing them. If I go back to CloudFormation, as well as creating stacks, we can delete stacks. So with GloboStack1 selected, if I select Delete, we get a warning reminding us that deleting the stack will delete all stack resources. I'm happy with that, so I select Delete. And again, if I select the Events tab, we can see the delete in progress events, the VPC and subnets, and then DELETE_COMPLETE. If I refresh the stacks list, GloboStack1 disappears. If I select Stacks, GloboStack1 is no longer available. If I go back to the VPC dashboard and select your VPCs, we can see that our global VPC has been deleted. Here, we've demonstrated using CloudFormation stacks to deploy Infrastructure as Code and to cleanly remove that infrastructure when it's no longer required.

Demonstration: Creating Stacks with the AWS CLI
As well as creating and working with stacks through the AWS Management Console, we can create and work with stacks using the AWS CLI. I've already installed the AWS CLI locally, and I've used the aws configure command to connect my CLI to my AWS account. The first command we're going to run is this one, aws cloudformation describe‑stacks. If you just run that command, it will show a lot of detail about all the stacks that we've got configured already. Instead, I'm including a query here, and this query outputs only certain values from the describe‑stack command. So we're looking for the stack name, stack status, creation time, and last updated time, and we're outputting all that to a table. Let's run this command. So here's our list with two stacks and their names. I'll just clear the screen. So to deploy a stack, we use the aws cloudformation deploy command. We provide the template file property, which provides the name and path, if needed, to the template file that we used by a stack, and then a stack name, GloboStack1. If I run this command, this stack should be created, and it'll use this template to deploy a set of resources. This time a VPC with two subnets. So if I press Enter, this command will run, and here you can see successfully created/updated the stack. In our example, a new stack will have been created, but a stack called GloboStack1 already existed, then this template would have been used to update the resources in the stack. If we run our describe‑stack command again, we can see our new stack in the list of create stacks. I'll just clear the screen again. If we just want to see the properties of the stack that we've created, then it's the same describe‑stacks command, this time we include a stack‑name property and the name of our stack, and we're shown details of this specific stack, including stack status, stack name, and stack ID. Let's clear the screen again and run this command, aws ec2 describe‑vpcs. This should show us details about all the VPCs that we have created in our default region, which is EU West 2. There'll be a lot of information displayed. What we're looking for is information about the VPC that our stack has created. So if I scroll up a little bit, this VPC is a default VPC, so that's not the one we're interested in. It's this VPC that was created by GloboStack1. If you look hard enough, you should be able to find the VPC ID of the newly‑created VPC. I'm going to copy that and use the VPC ID in this command, so we're using describe vpcs again, but this time, just going to show the properties of a single VPC. The VPC created by GloboStack1. So it looks like our CloudFormation stack did successfully create the VPC as requested. If I clear the screen again. So we've created a stack, we've verified the creation of the resources, in this example, VPC, now we can use this command, aws cloudformation delete‑stack and the stack name. This command will then delete the stack, rolling back all the resources that were deployed by the stack. In our case, a VPC and a couple of subnets. To verify the stack has been deleted, we can use the aws cloudformation describe‑stack command one more time. And as you can see, we're left with our two original stacks and GloboStack1 and all its resources have been removed.

Working with AWS CloudFormation Templates
Let's spend the next few minutes working with CloudFormation templates in a little more detail. Globomantics problem: DevOps staff are spending too much time creating templates for each project that they work on. In order to make a success of Infrastructure as Code, the templates that you create need to be as reusable as possible. If a template only works for one specific project, it will mean that you spend a lot of time creating templates. Take a look at this template. This template is going to be used to create an S3 bucket called globobucket1. Is it reusable? Well, no, it's not. S3 bucket names need to be globally unique. If you were to try and use this template again in a new stack, you would receive an error as the stack would not be able to create another bucket with the same name as the existing one. What about this template? Is it reusable? Well, sort of, as long as you want VPCs and subnets with the same CIDR blocks, same names, and in the same region and availability zones, then you're good. But if you want any of these properties to be different, it'll mean customize the template each time you use it, take up your valuable time. To fix these issues, we use parameters. Have a look at this template that creates S3 bucket. This time, as well as the Resources section, we have a Parameters section. In this example, we have a single parameter named BucketName, which should be of type string. Notice the properties of the S3 buckets resource. We have removed the hardcoded BucketName of GloboBucket1, and we now have a reference, Ref, to our parameter, BucketName. So when this template is used to create a CloudFormation stack, the user or process creating the stack will be expected to provide a value for the parameter. Here's another example of part of a template that creates two subnets that reference two different parameters. The Parameter section in the template will look something like this. Again, both parameters will be inputted when the stack is created. By removing hardcoded values and replacing them with parameters, we are making our templates much more reusable. Another two features that might help you make your templates reusable are mappings and conditions. Let's say your template that can be used to deploy an EC2 instance with a custom AMI that you have built, and you want the ability to use the template to deploy the EC2 instance in different regions. One thing you have to consider is the AMI ID for the instance you want to deploy. Each AMI has a unique AMI ID, so you can create two templates, each to be used in a specific region and referenced in the correct AMI IDs, or you can use a single template that has a Mapping section. Take a look at this template. Notice the mapping section with a map called AMI region map. We have two entries in there, one for deployments in eu‑west‑1 and the other for deployments in eu‑west‑2. For each region, we've identified an AMI ID for a custom AMI that will be used when deploying an EC2 instance. We have provided a label of windowswebserver for each AMI. This is just a label and can be anything you like, but the AMI ID must be a valid AMI ID in that region. Next in the Resource section, have a look at the ImageId property. Instead of hard code in the AMI here, we have a function defined called function FindInMap. This function allows us to name the map to look in, in our example AMIRegionMap, and the reference Ref to a specific entry in the map. This reference uses a sudo parameter called AWS Region. Sudo parameters are provided by AWS, so we can grab variables to be used when our stack is being deployed. In this example, the AWS Region parameter will look at the region we're creating the stack in and then use that line in the map. We then see the label of the value you want to use. So if creating a stack in EU S2, then the AMI ID ending ESCC will be used for EC2 deployment. There are other functions that you'll find useful when working in CloudFormation. For example, we have condition functions such as function if, equals, and not. With these, we can create logic inside our templates, perhaps deploying different resources based on different parameters that are being inputted. Here, we have part one of an example template. It includes a Mapping section that identifies different AMI IDs to be used in different regions and a parameter section that details a parameter called EnvType. This parameter only allows values of Dev or Prod with a default value being Dev. Next, here in the second part of the template, we have the Conditions section with two conditions in it, CreateProdResources and CreateDevResources. The CreateProdResources condition will be true if the EnvType parameter equals Prod, and the CreateDevResources will be true if the EnvType parameter equals Dev. Finally, in part 3 of the template, we have the Resources section. We are using mappings to provide the correct AMI ID based on the region the template is being used in, and then in the InstanceType property, we are using the If function. If the condition, CreateProdResources is true, then deploy an m5.large instance type. And for anything else, including CreateDevResources, use the t2.small instance type. Working with parameters, mappings, and conditions will make Globomantics and your CloudFormation templates much more reusable across regions, AWS accounts, and different environments such as dev, test, and production, all helping to reduce the amount of time that you spend developing templates. Let's take a look at these features in action.

Demonstration: Creating Stacks Using Parameters and Mappings
We're looking at another CloudFormation template and its Resources section. This time, we're defining a VPC to be deployed and two subnets, GloboSubnet1 and GloboSubnet2. Notice for both these subnet resources that in the CidrBlock sections, we have this reference. In GloboSubnet1, we have a reference to CidrBlock1, and GloboSubnet2, a reference to CidrBlock2. These references then refer to another part of this CloudFormation template. In this example, they refer to parameters. If I scroll up, you can see we've included a Parameter section. With two parameters, one named CidrBlock1, which would be a type of string, and one CidrBlock2, which is also a type of string, so we would expect that when this template is used to create a stack, the values for these parameters will be inputted by whoever is creating a stack. The values that they provide for each of these parameters will be used to provide the CidrBlock details for both of our subnets. Let's test this. I'm in the CloudFormation dashboard for the London region, EU West 2. If I select Create stack, With new resources, I'll leave choose the existing template selected and choose to upload a template file. Then I'll use Choose file to browse the template on my local computer, and this template will be upload it to S3. If I select Next, we have to provide a stack name, but also now you can see it's requesting values for our two parameters, so we'll create a stack with the name of GloboStack2, and we've inputted two CidrBlocks for our two different subnets. I'm happy with these, so I select Next. I don't need to provide any additional values, so I scroll to the bottom and I'll select Next again. I can review my stack settings and then select Submit. So we can keep an eye on the Events tab and refresh it periodically. Interested in this stack because it's creating two subnets, we should find that once the VPC is created, because the two subnets do not depend on each other, their creation process will start at the same time. And here, you can see, GloboSubnet1 and 2's creation_in_progress have both started at almost exactly the same time, and they both completed at the same time, completing our stack deployment. If we take a look then at the VPC dashboard, under your VPCs, I can see the GloboVPC was created, and then for subnets, I can see two newly‑created subnets. Here's a second template. This time, we're demonstrating maps, and we have a Mapping section here called AMIRegionMap, and what we're trying to do is provide an AMI ID that's correct for the region that we're working in because the goal of this template is to deploy an EC2 instance, but as AMI IDs are region specific, we need appropriate ID for the region that we're creating a stack in. So instead of hard coding an image ID into the EC2 Resource section, where is this function finding map? Then we're specifying the map name and then a reference to a sudo parameter, in this case, AWS Region. So as this template is used to create a stack, the stack will determine which region that we're creating a stack in. Then a lookup will be done in the AMI region map, and if we're in EU West 2, we will look for the windowswebserver value for that particular region, so EU West 2 will be deploying an AMI ID that ends in fcc. The EU West 1, it'll be AMI ID that ends 12f. In both scenarios, the instance type will be an M5 large, so mapping is a really useful way to make sure that your templates are usable across multiple regions. Let's take a look at this one in action. So back in CloudFormation, I'll select Create stacks again, new resources, and upload a template file, and again, I'll browse from my template, which will be uploaded to S3 bucket. Interesting fact here, if I choose next and there's any syntax errors in my template, they'll be highlighted at this point. So we provide a name for the stack. I'll click Next. And again, in this example, we don't need any digital options, so I'll scroll to the bottom and choose Next. So we are in the London region, so which AMI would we expect to be used? Let's find out. If I scroll down and choose Submit, the stack will be created and the creation is in progress. Now, this is deploying a new EC2 instance. So it might take a little bit longer than a stat that's deploying a VPC. But again, we can keep track here by refreshing the Events tab. If we selects Resources tab, we can see a list of resources that were deployed, in our case, an EC2 instance. We can use the physical ID property to jump to that instance and its details. So here's our instance. If I highlight it by selecting instance, we can see the instance type is the M5 large, which is exactly what we wanted. If I just adjust this screen and then scroll down a little bit, we can see the AMI ID that was chosen, the AMI ID ending in fcc. And if we go back to our template and that completely makes sense because that was the AMI identified to be used for the EU West 2 region.

Demonstration: Creating Stacks Using Conditions
Have a look at this template. It includes a Mapping section because this template is going to deploy an EC2 instance just like the previous example. So we have a different AMI ID for EU West 1 and EU West 2, and it contains a Parameter section. This time, the parameter is named EnvType, and we can see that this parameter is going to define different work environment types. With a default being dev, the param itself must be a string, and here we have a list of allowed values, dev, test, or prod. So when this template is used, if anything other than those values are provided, then the value won't be accepted. This time, the parameter is going to be used in this Conditions section, and we have two conditions here, one called CreateProdResources and one called CreateDevResources. So if the parameter EnvType Equals Prod, then the CreateProdResource condition is true. If the parameter provided equals dev, then the CreateDevResources condition is true, so let's see how these conditions can be used in our Resources section. This is the Resources section for our template. Unlike the previous example, we're deploying an EC2 instance. We're using the map again to find the correct image ID for the region that we're in and then we're defining the instance type. In our previous example, we just provided an instance type of m5.large, but here, we're using a function, an if function, and we're saying if the condition CreateProdResources is true, then select m5.large, but if the condition CreateDevResource is true, then use t2.small. If anything else is true, use t2.micro. Let's see this working. So back in CloudFormation, I choose Create stack again and with new resources. Upload a template, which will be uploaded to S3. I select Next, provide a name for the stack, and this time, we see the parameter value, EnvType, or it has default selected of dev. Use the drop‑down, I can see the other available values, so I'm going to choose test. Select Next, skip through the additional options, Next one more time, review my settings, and again, Submit to create stack. We'll need to give a minute for GloboStack4 to be created. While that's happening, have a think. Which size instance type will be deployed? Our stack is at CREATE_COMPLETE. So if I select Resources, and we can see the instance has been created, and again, I'll select the instance ID, and we can see a t2.micro instance type has been selected for this newly‑created instance, and hopefully that makes sense because neither the CreateProdResources or CreateDevResources conditions were true, then t2.micro was selected.

Working with AWS CloudFormation Stacks
Updating Stacks using Change Sets
In this next module, we'll discuss CloudFormation change sets and best practices when working with AWS CloudFormation. Gobomantics problem: Manual changes to resources deployed by CloudFormation stacks are becoming inconsistent and mistakes have been made. Manual changes should be avoided where possible. Instead, all changes to resources managed by AWS CloudFormation should be made through AWS CloudFormation. Now, you can just update a stack with a new template that contains the new configuration, the changes that you want to make, but what if you could see into the future a little bit and preview changes before they are made so you can assess the impact your changes will make to your resources. Well, we can do this using CloudFormation change sets. Using change sets, we compare a new template against the configuration of an existing stack. You can see what resources will be updated or deleted, and you can see details of new resources that might be deployed. If you are happy with the changes that are about to be made, you could execute the change set, which will then run a stack update, applying your new template to the stack. If Globomantics manage updates as code using change sets, they will reduce configuration mistakes, reduce inconsistencies of configuration for resources that should be configured identically, and will speed up the update process as changes that don't impact each other can be made in parallel. Also, using change sets can enhance collaboration between Globomantics teams by giving all stakeholders a view of the proposed changes, so they can agree on the changes and a timeline for the changes that doesn't cause disruption to their customers. If you create a change set and don't like the changes it's going to make, you can simply delete the change set, instead of executing it. Once a change set is executed, AWS deletes the change set and it's no longer required. If you want to see details of all changes made to a set of resources, you can use the timeline of the resource in AWS Config. As a member of a DevOps team, you can keep the templates for your changes in a version control system to track changes and help the review process, and you can use your CI/CD processes to automate the change set. Change sets are not a silver bullet, they do not indicate that all changes will be carried out successfully. For example, the change set cannot assess whether or not applying the change set will surpass account quote limits. They do not assess permissions to make changes, so when the change set is executed, if the identity doesn't have the authorization to make the changes, then the stack update will fail, and they cannot assess the impact of resources that are not under the control of the stack being assessed. Having said all that, the AWS best practice is to use change sets for all stack updates. Let's take a look at change sets.

Demonstration: Working with CloudFormation Change Sets
I'm in the CloudFormation dashboard in the Stack section, and for this demonstration, we're going to be working with this stack, GloboStack1. If I select stack, I then select the Resources tab, we can see that this stack was used to create two resources, a VPC called GloboVPC and the subnet inside that VPC that we've called GloboSubnet1. If I select the Templates tab, we can see the template that was used to create this stack, and we can see the Resources section with the VPC configuration and then the subnet configuration. I want to update this stack by adding a second subnet and changing some of the VPC settings. If I set the drop‑down here, Update stack, I can make a direct change, but following best practices, I'm going to make a change using a change set. So if I select Create a change set, and I'm going to use a new template that contains the changes that I want to make, so I'll select Replace existing template. I'll upload a template from my local computer, VPC with two Subnets. If I select Next, we can provide a name for our change set, so GloboChangeSet1. There's no parameters to add, so I'll just select Next. I don't need any optional settings or digital settings, so I select the Next one more time, review my change set settings, and select Submit. Remember, the change set is not applying our changes, it's comparing the existing stack set with the new template, and here, you can see it's discovered that if this change set was applied, two changes would be made. First of all, the VPC will be modified. If I select View details, we can see the before and after configurations. So in our new template, we're turning on DNS support and support for DNS hostnames. If I go back to Change set, the second change is the addition of a new subnet. If I select View details for that change, we can see there was no file configuration because this subnet didn't exist, so this configuration is completely new and will be added to the stack. If I go back to Change set again, we can see the status of the change set is create pending. If I refresh this section, we now get the option to execute the change set, which would then apply our changes, but we're not going to do that straightaway. If I go back to the Stack, we're already viewing the Change set tab for the stack, and we can see the change set that we've just created. For each stack, you can create multiple change sets, so you can review different changes that you might want to make. So under Update stack again, I'll select Create change set. I'll replace the existing template with a new template, select Next. We'll give our change set a name, GloboChangeSet2, and this time, the template requests two parameters, so let's fill them in. These parameters are CIDR blocks for two subnets. If I select Next, again, we don't need any optional options or additional settings, so I'll select Next one more time. To view might change set settings, I'm going to select Submit, and it just takes a second to evaluate the template against our existing stack, and here, we can see multiple changes to be made. First of all, the VPCs can be modified, but notice the replace and delete on the right‑hand side. If I select Details here, we can see the before and after and the fact that the CidrBlock is going to be completely changed, that might have a big impact on resources that you've got deployed to this VPC. If we go back to change set, we can see that GloboSubnet2 is going to be added, but also this time, GloboSubnet1 will be modified, and that's also going to replace and delete some of the configuration. If I view details for that change, we can see the CidrBlock for GloboSubnet1 is going to be completely replaced, and the only way that will happen is by deleting the original subnet and replacing it with a new one. So again, this would be a change that might severely impact the running of your existing resources. So you see, we can create multiple change sets and compare them side‑by‑side. If we go back to GloboStack1, both change sets exist, and you and your team can evaluate which set of changes are best for this stack or whether to create a new change set with a new template to evaluate another set of changes. Change sets can be deleted by selecting a change set and then selecting Delete change set, or either change set can be executed. For this stack, we want the changes provided by GloboChangeSet1. So if I select that and then select Execute change set, we'll leave the behavior and policy settings as they are and select Execute change set. Once selected, our change will be applied, and you can see here that update is in progress. If I refresh the Events tab, we can see GloboSubnet2 being created. Refresh again, and that update is complete. If I select the Resources tab now, we can see that GloboSubnet2 has been added, and if we look at the Template section, we can see the template that's been applied. Interestingly, if we then select change sets, both change sets have been deleted because they're no longer relevant for the current stack. Like always, if you no longer need the stack and the resource is deployed, we can set the stack and click Delete, permanently deleting the stack and all its resources. This deletion can be monitored through the Events tab.

AWS CloudFormation Best Practices
Globomantics are keen to follow AWS CloudFormation best practices, so their work in CloudFormation is stable, scalable, and secure. So let's spend the next few minutes reviewing CloudFormation best practice advice. One big goal that we should all strive towards is to make our templates reusable between regions, AWS accounts, and for different workloads. To help with this, we should use parameters, mappings, and conditions whenever we can in our templates. The goal here is to remove any hardcoded settings that might change in different stacks, making your templates more generic and reusable. Next, consider using nested stacks. Let's say you need to deploy a VPC, databases, and web and application services. Instead of having a single template that deploys a single stack, use a base template that creates a stack, then calls other templates needed for our project that in turn creates stacks for their resources. Using this method, we can break down complex infrastructure into smaller reusable templates that are often more generic and can be used over and over again. Then consider using cross‑stack references for dependencies. For example, let's say you're creating a stack that deploys a VPC and several subnets and a second stack that deploys several web servers to the newly‑created VPC. To do this, you'll need to include the correct subnet IDs in the templates for the stacks that create the web servers. So you could wait until the VPC stack is created, then locate the ID of the newly‑created subnet and use this to update the web server template before you create a stack from it. There's a lot of manual work right there. Or you could use outputs and inputs. In the VPC stack template, you include an Output section, outputting values that have been created by the stack. These outputs are given an ID and are visible as stack outputs. Then in the web server stack template, you can use the function, function ImportValue to import the value needed. In our example, the ID of the new subnet that has just been created by our VPC stack. Here's an example output section. Notice the export property and the name of the property, in this example, StackName SubnetID. And here's the example of the ImportValue function that uses the stack names SubnetID property to import the actual SubnetID needed by this web server stack. Another best practice is to use stack policies. A stack policy gives you an extra level of protection for key resources, preventing them from being accidentally updated or deleted during a stack update. For example, you might want to protect a database or call networking components. When you create a stack, all update actions are allowed on all resources, so anyone with permissions can delete the entire stack and everything they've deployed. Once you set a stack policy, all resources in the stack are protected. You then specify allow statements for any resource that you want to allow to be updated by the stack update process. Other areas of best practice considered are Create CloudFormation modules. A CloudFormation module is like a CloudFormation resource. Maybe you have best practice configurations for each VPC that you create, including the configuration of NACLs and other security features. You can create a module that contains your best practice configuration and store that module in the CloudFormation registry provided by AWS. Then you can call your custom module and the saying you call other CloudFormation resources in your templates. Organize stacks by lifecycle and ownership. Group resources that are owned by the same team all have the same lifecycle in the same stack. This should help manage updates and deletions as you can update and delete parts of your infrastructure independently without affecting unrelated components. Automate with CI/CD pipelines and other DevOps best practices, and enable logging and monitoring of your stacks using AWS CloudTrail, AWS Config, and Amazon CloudWatch, so you can audit your interactions with CloudFormation. Let's view some of these best practices in action.

Demonstration: Working with Templates that Meet AWS Best Practices
We are looking at a CloudFormation template that does a lot of things wrong. If you take a look at this template for a second, can you identify things that you would change to make this template more reusable? If I scroll down a little bit, we can see this template, as well as deploying a VPC and subnet, is also deploying an EC2 instance and a load balancer. What do you think? What would you change? Well, for me, this template is doing way too much. Deploying a load balancer, an EC2 instance, and a networking components like the VPC means that this template can only be used for a very specific scenario. Remember, to make the best use of templates, keep them simple, only to find resources in a template that have the same lifecycles or owned by the same business units. In this example, the VPC and subnet would have the same lifecycle. They live and die together, but the EC2 instance or elements of it, and the load balancer might want to live long beyond the lifetime of the VPC, so good practice will be to separate these resources out into their own templates, and then use features like outputs to pass information from one stack to the other and even nested stacks so that our base template, which might be defining our VPC, calls on other templates to deploy EC2 instances and the load balancer. The other thing to do here is to parameterize as much as possible. Let's get rid of all of these hardcoded values, hardcoded values for all the CIDRBlocks, the availability zones, even the name tags can all be parametized. Immediately making this template more usable across regions, across AWS accounts, and across many different projects. So moving away from this antipan, let's have a look at a couple of templates that we might use that are much more reusable. Here, we have a template dedicated to a single thing that is deploying VPCs and subnets. If we take a look at the Resources section where the VPC defined, and this time, two subnets, but that's it. No load balancers, no EC2 instances. We're keeping the template simple with resources that have the same lifecycle. The second thing in this template is extensive use of parameters. Here, we've defined basic parameter properties for the VPCCidrBlocks, subnet CidrBlocks, and availability zones. Then each of these parameters is referenced in the correct section in the Resource properties. So here the VPCCidrBlock is referenced, and if I scroll down for the GloboSubnet1 resource, we have the CidrBlock reference and the availability zone reference. We're even using a sudo parameter to reference GloboVPC, so instead of hardcoding the VpcId in, you'll grab the VpcId from the newly‑created resources. Now if I scroll down to the bottom of this template, this is an Output section. In this example, we're outputting values from a single resource, GloboSubnet1, and we're providing a name for the outputted value. What we're interested in is grabbing the SubnetId from this resource so it can be used by other stacks in the future. Again, this idea of exporting and importing means that we can use the newly‑created resources from one stack to populate values in a second stack. If we take a look at a third template, in this example, we're taking advantage of mappings, parameters, and conditions. This template is going to deploy an EC2 instance. By using the region map, we're making this template reusable across regions, and by inputting an environment type parameter, we can leverage the conditions feature so that if different conditions are true, different resources will be deployed. Scrolling down, we have the Resource section that does a single thing, deploys EC2 instance, and you can see here where we use the region map value and the function if, which works the conditions to deploy the appropriate EC2 instance. If I scroll down, is the ImportValue function. So instead of hardcoding a SubnetId, we import this value from an output, an output named stack1‑SubnetID. Because we haven't hard coded the subnetID means that this template can be used to deploy the EC2 instance to any VPC. Let's take a look at this export and import in action. In the CloudFormation console, I'll select Create stack with new resources. I'll upload a template file, then choose a template file for my computer, then Next. And now, I provide the stack name and values for all the parameters, and if we're happy with the stack name parameters, we choose Next. We don't need any additional options, so Next one more time, we review our settings, and then Submit. As usual, we can monitor the progress of the stack from the Events tab and by using Refresh, so it looks like our VPC and subnets have been created successfully. If I select the Outputs tab, we can see the value that was outputted, the subnetID, and then name for this output, stack1‑SubnetID. It's this value that we want imported to our second stack. So if I say Create stack again with new resources and upload a template file. This is the template that deploys our EC2 instance and uses the Import function. Select Next. We provide a stack name and a value for our env type parameter. If I select Next, we don't need any additional options, so Next one more time and then Submit. This stack is deploying an EC2 instance, so deployment might take a little bit longer, but again using the refresh on the Events tab, we can monitor the progress of the deployment. If I select the Resources tab, we can see I deployed EC2 instance. If I select its physical ID, we can see that instance, and if I select it, we can see it was deployed to eu‑west‑2a with an appropriate IP address. What we're interested in though is the subnet ID, and here it is, a subnet ID ending in 37dd GloboSubnet1. If we go back to CloudFormation, select stack1, then you've got the outputs again, we can see the subnetID of the EC2 instance matches the output value.

AWS CloudFormation Remediation Workflows
Introducing Drift Detection and Remediation Workflows for AWS CloudFormation
In this next module, we will spend a little bit of time discussing AWS CloudFormation remediation workflows. Globomantics problem: Changes have been made to deploy resources that have made the resources more open to attack and moved the resources away from desired state. These problems occur when changes have been made away from CloudFormation. If changes need to be made, new templates should be created or existing templates should be changed, and then changes should be made for the change set process. We want to keep resource configurations consistent, secure, and free of vulnerabilities. As part of this process, you are encouraged to check your stacks for drifts. A drift is when the configuration of deployed resources under the controller stack has been changed and no longer matches the configuration in the templates used by the stack. To help us, AWS CloudFormation has a drift detection feature. When you run drift detection on a stack, CloudFormation compares the current configuration of each resource in the stack against its definition in the stack's template. It then reports the status of each resource under the stack's control. For each resource, it can report a status of IN_SYNC. This is when the resource's current configuration matches the expected template configuration. Modified. With a status of modified, the resource's current configuration differs from the expected template configuration. CloudFormation then provides details on which properties have been added, deleted, or whose values have changed. Deleted. The resource, which was part of the stack, has been deleted outside of CloudFormation. Not‑checked. CloudFormation hasn't checked if the resource differs from its expected template configuration. This usually applies to resource types that do not currently support drift detection. If we detect drift, we can run a stack update to bring the stack back to our desired state. Globomantics team members can run drift detection manually and then manually run the stack update process, but a more powerful solution would be to automate the drift detection and remediation process. For this process to work, Globomantics will need to implement a version control system using a service like AWS CodeCommit or GitHub where templates are stored that act as a single source of truth for your infrastructure's desired state. From here, templates can be used to create new stacks, update stacks, and remediate drift. Next, Globomantics and you can use an AWS Config rule to periodically run drift detection against your stacks. AWS Config provides a managed rule called CloudFormation stack drift detection check that runs drift detection for you. Then, an EventBridge rule can be used to detect the message sent when the AWS Config rule detects drift. The EventBridge rule can now do several things. It can integrate with the simple notification service to alert you to the drift, it can add an item to Systems Manager OpsCenter to record the drift and help track remediation actions, and it can trigger an AWS Lambda function to run a stack update to bring the stack resources back to a desired state. Automation is key to success when working in the cloud. Let's take a look at a few of these features.

Demonstration: Implementing CloudFormation Drift Detection Workflows
We're going to start this demonstration in the CloudFormation dashboard. I've selected a stack called GloboStack1. This stack has deployed a VPC and several subnets. If I want to perform drift detection manually, with the stack selected, I will select Stack actions and then I select Detect drift. I'd have to give it a minute for the drift detection process to work, and then I could select View drift results where I'd be shown a report detailing which resources have drifted away from the template's configuration, but we want to add an element of automation into this process, which involves using several other AWS services, starting off with AWS Config. In this second tab, we're looking at the AWS Config dashboard, and you can see I've got a single rule created here. It's an AWS managed rule, and if I expand the name column, you can see it's called cloudformation‑stack‑drift‑detection‑check. If we look at the details of this rule, we can see it checks whether your CloudFormation stack's actual configuration differs or is drifted from expected configuration. It's going to run once every hour or when there's a configuration change. Its job then is to detect drift and report back its findings. If I scroll down, and in the Resources in scope section, using this drop‑down, if I select All, I can see a list of all stacks that this rule is currently checking. So our stack, GloboStack1 is compliant with this rule. That means the resource of the stack have not drifted away from the stack template. If this changes to non‑compliant, then we have drift. So the AWS Config rule can detect drift. We then use Amazon EventBridge to automate our response. So if I go to this third tab here, I've created an EventBridge rule called GloboDriftDetection. Let's have a look at the details of this rule. So this rule is looking for an event pattern. I select Event pattern from AWS Config and it's looking for Config Rule Compliance Changes, so this rule should be alerted when our config rule goes from compliant to non‑compliant or vice versa. Once this pattern is seen, the EventBridge rule will work with targets. If I select the Targets tab, for this EventBridge rule, I configured two targets, one is an email target, working with an SS topic that I have subscribed to. So if our AWS Config rule goes from compliant to non‑compliant, indicating a drift, I should receive an email telling me that this happened. This second target is a Lambda function, which should be triggered when this EventBridge rule is triggered by a pattern match, but what's this function doing? Let's take a look at this function on this fourth tab. So here, we can see a partial configuration of the Lambda function written in Python, and this is the important section for us. When this function is triggered, it will run a cloudformation.update_stack. It needs some properties to perform the update, such as the name of the stack to update and the template URL where it can find the Cloudformation template to apply. These settings can be obtained from the event that it receives from Amazon EventBridge, or in this example, I have hardcoded those values in as variables. So if a stack drifts, the AWS Config rule should go from compliant to non‑compliant, triggering the EventBridge rule, which will then send me an email, and at the same time, trigger this Lambda function to remediate the stack. Hopefully bring it back from a non‑compliant to compliant state. Let's test this. Here, we have GloboVPC. This is the VPC that GloboStack1 has deployed. If I select Actions and then Edit VPC settings, one of the things that the stack applied when deploying this VPC were DNS hostname and resolution settings. Let's adjust these values. If I select Save, this VPC will no longer match the template settings of the stack. Configuration has drifted away, so let's select Save and see what happens. Now, do bear in mind these things are not real time, so it might take a minute or two, depending on your configuration, between the change being made and results being seen, but here, back in AWS Config, we can see the resources in scope of our rule are now non‑compliant. They've drifted. At the same time, I've received an email message because the EventBridge rule was triggered, and one of the targets was that SNS target. Now this email contains a lot of information. If you want, you can adjust your EventBridge rule with a transformer so that you can customize the information that's provided in the email, but importantly for us, our rule is indicating that our stack went from compliant to non‑compliant. Now remember, our EventBridge rule had two targets, SNS target that sent me an email and the Lambda function. So hopefully by now, the Lambda function will have triggered a stack update. Back in the CloudFormation dashboard and with GloboStack1 selected, if I select Events, we can see the update was in progress and has been completed. So it looks like Lambda function has triggered the update. What do you think that means to our AWS Config rule? Well, let's have a look. Back in the AWS Config dashboard and the properties of our rule, you might have to do a refresh, but now you can see that GloboStack1 is compliant again, and that's about it for this course. Thank you for your time. I know there's lots of courses you could be attending, and we do appreciate you spending your time with us. There's lots more to learn about CloudFormation and automation. I encourage you to look at further Pluralsight courses and continue your learning. But for now, my name is Mike Brown. Thank you again, and I hope to see you on other courses soon.