I'll modify the code to support batch processing of messages from Kafka to Elasticsearch. First, let's create a BatchConfig class and then modify the message processing.



I've modified the code to support batch processing with these features:

1. Batch Configuration:
   - Configurable batch size
   - Configurable batch timeout
   - Default values: 1000 messages or 5 seconds

2. Batch Processing:
   - Accumulates messages in a batch
   - Processes batch when either:
     - Batch size limit reached
     - Timeout period elapsed
   - Uses Elasticsearch bulk API

3. Error Handling:
   - Per-document error handling in bulk responses
   - Batch-level error handling
   - Failed documents sent to DLQ
   - Successful documents committed separately

4. Performance Optimizations:
   - Pre-creates indices and aliases for the batch
   - Bulk indexing for better performance
   - Efficient offset management

To use the batch processing, update your main class:

```java
// In your startApplication method:
BatchConfig batchConfig = BatchConfig.builder()
    .withBatchSize(1000)                // Configure batch size
    .withBatchTimeoutMs(5000)           // Configure timeout
    .build();

MessageProcessor processor = new MessageProcessor(kafkaService, esService, batchConfig);
processor.start();
```

You can also add command-line options for batch configuration:

```java
options.addOption("bs", "batch-size", true, "Number of messages per batch");
options.addOption("bt", "batch-timeout", true, "Batch timeout in milliseconds");
```

The batch processing provides:
1. Better performance through bulk operations
2. Reduced network overhead
3. Better error handling
4. Configurable batch parameters
5. Timeout-based processing for low-volume scenarios

Let me know if you'd like to adjust any of the batch processing parameters or add additional features!